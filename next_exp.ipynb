{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense,Conv2D,MaxPooling2D,UpSampling2D,BatchNormalization\n",
    "from keras.models import Model,Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = cifar10.load_data()\n",
    "# # This is our input image\n",
    "# input_img = keras.Input(shape=(784,))\n",
    "# # \"encoded\" is the encoded representation of the input\n",
    "# encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "# # \"decoded\" is the lossy reconstruction of the input\n",
    "# decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# # This model maps an input to its reconstruction\n",
    "# autoencoder = keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = x_train.astype('float32') / 255.\n",
    "# x_test = x_test.astype('float32') / 255.\n",
    "# x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "# x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "# print(x_train.shape)\n",
    "# print(x_test.shape)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "# x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "# x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 32, 32, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 16, 16, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 16, 16, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 8, 8, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 8, 8, 8)           1160      \n",
      "                                                                 \n",
      " encoder (MaxPooling2D)      (None, 4, 4, 8)           0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 4, 4, 8)           584       \n",
      "                                                                 \n",
      " up_sampling2d_15 (UpSamplin  (None, 8, 8, 8)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 8, 8, 16)          1168      \n",
      "                                                                 \n",
      " up_sampling2d_16 (UpSamplin  (None, 16, 16, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 14, 14, 32)        4640      \n",
      "                                                                 \n",
      " up_sampling2d_17 (UpSamplin  (None, 28, 28, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,320\n",
      "Trainable params: 10,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_img = Input(shape=(32, 32, 3))\n",
    "\n",
    "x = Conv2D(16, 3, activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D(2, padding='same')(x)\n",
    "x = Conv2D(16, 3, activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(2, padding='same')(x)\n",
    "x = Conv2D(8, 3, activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D(2, padding='same',name='encoder')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, 3, activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D(2)(x)\n",
    "x = Conv2D(16, 3, activation='relu', padding='same')(x)\n",
    "x = UpSampling2D(2)(x)\n",
    "x = Conv2D(16, 3, activation='relu')(x)\n",
    "x = UpSampling2D(2)(x)\n",
    "decoded = Conv2D(3, 3, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "b1 = Flatten()(input_image)\n",
    "b1 = Dense(64, activation='relu')(b1)\n",
    "b1_out = Dense(32, activation='relu')(b1)\n",
    "\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "# autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_38\" is incompatible with the layer: expected shape=(None, 32, 32, 3), found shape=(None, 3072)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/sumankunwar/workspace/neuralnetwork-jpeg/next_exp.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sumankunwar/workspace/neuralnetwork-jpeg/next_exp.ipynb#ch0000024?line=0'>1</a>\u001b[0m autoencoder\u001b[39m.\u001b[39;49mfit(x_train, x_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sumankunwar/workspace/neuralnetwork-jpeg/next_exp.ipynb#ch0000024?line=1'>2</a>\u001b[0m                 epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sumankunwar/workspace/neuralnetwork-jpeg/next_exp.ipynb#ch0000024?line=2'>3</a>\u001b[0m                 shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sumankunwar/workspace/neuralnetwork-jpeg/next_exp.ipynb#ch0000024?line=3'>4</a>\u001b[0m                 validation_data\u001b[39m=\u001b[39;49m(x_test, x_test))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/7n/1by73r111h998g7zrl9sz4ym0000gq/T/__autograph_generated_filefs647y6y.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_38\" is incompatible with the layer: expected shape=(None, 32, 32, 3), found shape=(None, 3072)\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=1,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(x_train, x_train,\n",
    "                epochs=1,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage import io\n",
    "\n",
    "def calculate_mse(imageA, imageB):\n",
    "\treturn mse(imageA, imageB)\n",
    "\n",
    "def calculate_psnr(imageA, imageB):\n",
    "\treturn psnr(imageA, imageB)\n",
    "\n",
    "def calculate_ssim(imageA, imageB):\n",
    "\treturn ssim(imageA, imageB)\n",
    "\n",
    "def compression_ratio(original, compressed):\n",
    "\treturn (original.size) / (compressed.size)\n",
    "\n",
    "def compare_images(original, compressed, title):\n",
    "\t# compute the mean squared error, peak signal noise ratio and structural similarity\n",
    "\n",
    "\tfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 4), sharex=True, sharey=True)\n",
    "\tax = axes.ravel()\n",
    "\n",
    "\t# setup the figure\n",
    "\tax[0].imshow(original, cmap=plt.cm.gray)\n",
    "\tax[0].set_xlabel(f'MSE: {calculate_mse(original,original):.3f}, SSIM: {calculate_ssim(original,original):.3f}')\n",
    "\tax[0].set_title('Original image')\n",
    "\n",
    "\tax[1].imshow(compressed, cmap=plt.cm.gray)\n",
    "\tax[1].set_xlabel(f'MSE: {calculate_mse(original,compressed):.3f}, PSNR: {calculate_psnr(original,compressed):.3f}, SSIM: {calculate_ssim(original,compressed):.3f}')\n",
    "\tax[1].set_title('Compressed image')\n",
    "\n",
    "\tplt.show()\n",
    "\n",
    "# initialize the figure\n",
    "fig = plt.figure(\"Images\")\n",
    "index  = np.random.randint(len(x_test))\n",
    "original = np.squeeze(x_test[index])\n",
    "compressed = np.squeeze(decoded_imgs[index])\n",
    "images = (\"Original\", original), (\"Compressed\", compressed)\n",
    "# loop over the images\n",
    "for (i, (name, image)) in enumerate(images):\n",
    "\t# show the image\n",
    "\tax = fig.add_subplot(1, 3, i + 1)\n",
    "\tax.set_title(name)\n",
    "\tplt.imshow(image, cmap = plt.cm.gray)\n",
    "\tplt.axis(\"off\")\n",
    "# show the figure\n",
    "plt.show()\n",
    "\n",
    "#compare image quality\n",
    "compare_images(original, compressed, \"Original vs. Compressed\")\n",
    "\n",
    "#calculate compression ratio\n",
    "cr = \"{:.4f}\".format(compression_ratio(original, compressed))\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=1,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1, n + 1):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gaussian_noise(X, sigma=0.1):\n",
    "    noise = np.random.normal(loc=0.0, scale=sigma, size=X.shape)\n",
    "    return X + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Conv2D(32, 3, activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "# x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "# x = layers.Conv2D(8, 3, activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D(2, padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = layers.Conv2D(32, 3, activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D(2)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D(2)(x)\n",
    "# x = layers.Conv2D(16, 3, activation='relu')(x)\n",
    "# x = layers.UpSampling2D(2)(x)\n",
    "decoded = layers.Conv2D(1, 3, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(25):\n",
    "    print(\"Epoch %i/25, Generating corrupted samples...\"%(i+1))\n",
    "    X_train_noise = apply_gaussian_noise(x_train)\n",
    "    X_test_noise = apply_gaussian_noise(x_test)\n",
    "    history = autoencoder.fit(X_train_noise, x_train,\n",
    "                epochs=1,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test_noise, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_train_noisy, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select input image\n",
    "index = np.random.randint(len(x_test))\n",
    "original_image = x_test[index]\n",
    "# plot the image\n",
    "plt.imshow(original_image)\n",
    "plt.gray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize compressed image\n",
    "compressed_image = decoded_imgs[index]\n",
    "plt.imshow(compressed_image)\n",
    "plt.gray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage import io\n",
    "\n",
    "def calculate_mse(imageA, imageB):\n",
    "\treturn mse(imageA, imageB)\n",
    "\n",
    "def calculate_psnr(imageA, imageB):\n",
    "\treturn psnr(imageA, imageB)\n",
    "\n",
    "def calculate_ssim(imageA, imageB):\n",
    "\treturn ssim(imageA, imageB)\n",
    "\n",
    "def compression_ratio(original, compressed):\n",
    "\treturn (original.size) / (compressed.size)\n",
    "\n",
    "def compare_images(original, compressed, title):\n",
    "\t# compute the mean squared error, peak signal noise ratio and structural similarity\n",
    "\n",
    "\tfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 4), sharex=True, sharey=True)\n",
    "\tax = axes.ravel()\n",
    "\n",
    "\t# setup the figure\n",
    "\tax[0].imshow(original, cmap=plt.cm.gray)\n",
    "\tax[0].set_xlabel(f'MSE: {calculate_mse(original,original):.3f}, SSIM: {calculate_ssim(original,original):.3f}')\n",
    "\tax[0].set_title('Original image')\n",
    "\n",
    "\tax[1].imshow(compressed, cmap=plt.cm.gray)\n",
    "\tax[1].set_xlabel(f'MSE: {calculate_mse(original,compressed):.3f}, PSNR: {calculate_psnr(original,compressed):.3f}, SSIM: {calculate_ssim(original,compressed):.3f}')\n",
    "\tax[1].set_title('Compressed image')\n",
    "\n",
    "\tplt.show()\n",
    "\n",
    "# initialize the figure\n",
    "fig = plt.figure(\"Images\")\n",
    "index  = np.random.randint(len(x_test))\n",
    "original = np.squeeze(x_test[index])\n",
    "compressed = np.squeeze(decoded_imgs[index])\n",
    "images = (\"Original\", original), (\"Compressed\", compressed)\n",
    "# loop over the images\n",
    "for (i, (name, image)) in enumerate(images):\n",
    "\t# show the image\n",
    "\tax = fig.add_subplot(1, 3, i + 1)\n",
    "\tax.set_title(name)\n",
    "\tplt.imshow(image, cmap = plt.cm.gray)\n",
    "\tplt.axis(\"off\")\n",
    "# show the figure\n",
    "plt.show()\n",
    "\n",
    "#compare image quality\n",
    "compare_images(original, compressed, \"Original vs. Compressed\")\n",
    "\n",
    "#calculate compression ratio\n",
    "cr = \"{:.4f}\".format(compression_ratio(original, compressed))\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the figure\n",
    "fig = plt.figure(\"Images\")\n",
    "index  = np.random.randint(len(x_test))\n",
    "original = np.squeeze(x_test[index])\n",
    "compressed = np.squeeze(decoded_imgs[index])\n",
    "images = (\"Original\", original), (\"Compressed\", compressed)\n",
    "# loop over the images\n",
    "for (i, (name, image)) in enumerate(images):\n",
    "\t# show the image\n",
    "\tax = fig.add_subplot(1, 3, i + 1)\n",
    "\tax.set_title(name)\n",
    "\tplt.imshow(image, cmap = plt.cm.gray)\n",
    "\tplt.axis(\"off\")\n",
    "# show the figure\n",
    "plt.show()\n",
    "\n",
    "#compare image quality\n",
    "compare_images(original, compressed, \"Original vs. Compressed\")\n",
    "\n",
    "#calculate compression ratio\n",
    "cr = \"{:.4f}\".format(compression_ratio(original, compressed))\n",
    "print(cr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
